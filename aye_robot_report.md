**
## Introduction
**
The first of the two google colab notebooks we ran operated on a major assumption: that the words composing a text are indicative of its genre.  It trains an algorithm to recognize a text is a recipe based on the words in a corpus of known recipes and 10,000 uncategorized texts from the Viral Texts project. Using a logistical regression model, the algorithm calculates the probability that a word is from a recipe or unclassified text. Then, it uses these probabilities to determine how likely it is that each text in the corpus is a recipe. Interestingly, the model determined the word “raspberry” was the most likely word to indicate a text was a recipe and not an uncategorized text.

At surface level this isn’t all that strange. As humans, we can predict that the presence of the word raspberry indicates a food related genre. However, the computer doesn’t know that the string “raspberry” is representative of foody-ness. All it knows is what we tell it. Our training data, then, must indicate that raspberry occurs a lot in recipes and almost never in things that aren’t already classified. So, how did the term raspberry wind up in our training data? Is this symptomatic of a 19th-century raspberry craze or perhaps a bias towards raspberries in the training data? My aim, here, isn’t to understand why our algorithm thinks raspberries are so indicative of recipes on a mathematical level. Rather, in this lab report I’m interested in the transformations that produced this raspberry phenomenon in the first place to contextualize it.

The Training Data: Avery, an RA on the Viral Texts Project, created this dataset to come up with a rough way to identify 19th century recipes. To do so, she pulled 19th century American recipe books from project Gutenberg. Avery defines “American-ness” based on the publisher’s location. She lifted 4 separate cookbooks from Project Gutenberg from which she pulled 1028 recipes. 2 of them—containing 827 recipes for a total 80.44% of the corpus—were written by the same author: Eliza Leslie of Philadelphia. Choosing these books wasn’t necessarily a bad choice. According to Wikipedia, Leslie’s cookbooks were some of the most popular in the US during the period. She also used ingredients she believed were strictly American and would be available in urban and rural areas alike. That being said, because Leslie’s recipes dominate 80% of the dataset, the topic model will have a propensity for recognizing recipes that share words characteristic of Leslie and perhaps fail to account for those of others. Was Eliza Leslie any more of a raspberry enthusiast than the average 19th century cookbook-author?

It's not possible for me to tag an additional 800+ recipes not written by Leslie, chuck them in the test dataset, and re-run the model. But I can compare the number of times she uses the word raspberry in cookbooks to that of other authors. Given that our model categorizes texts based exclusively on word occurrence, this should give us an ok idea of what’s going on.

## **Back into the matrix…**

First, I selected three different 19th century cookbooks from project Gutenberg for comparison. These fit Avery’s same criteria: they were published in the US in the 19th century. I selected these books at random.

Next, I recorded the total number of words in each plain text rendering of all 8 books and the number of times the string “raspberr” occurred in the texts. Lastly, I divided the number of “raspberr” occurrences by the total number of words to get a rough percentage of the work that was the word “raspberry” or “raspberries.” I call this very scientific value the raspberry index.

Analysis of this new corpus shows that most of the texts have a 0.3-0.4% raspberry index. Two books, _Domestic Cookery_ and _The Cook's Oracle,_ fall on the lowest end of the spectrum with a 0.01% raspberry index. One of Avery’s texts, on the other hand, has a much higher raspberry index than that of the rest with a score of 0.7%. This seems to be because this book, _Seventy-Five Receipts for Pastry Cakes, and Sweetmeats_ by Elizabeth Leslie, is a dessert cookbook. Most of the other books contain a pastry section that features raspberries, but there are not nearly as many raspberries throughout. Because Avery included this dessert book in the corpus, her four books have an average raspberry index of 0.032374634% while my 3 have an average index of 0.02864962666%.

 [results table](https://docs.google.com/spreadsheets/d/10CKL7Or1TwR8TpIJxhzzRr5ScS7yC427SWEKEwg480o/edit?usp=sharing)
## **Analysis**

My very unscientific findings indicate that Avery’s assumption that “recipe” is a coherent genre on the word level is probably not correct, especially not when using a small, biased corpus.

The model rated raspberry as the best word-predictor of a text being a recipe because 9.8% of Avery’s corpus came from a dessert recipe cookbook. Had she picked a more balanced corpus, the model probably would not have ranked raspberry as highly as it did. Furthermore, because the actual ingredients in recipes vary across sub-genre (sandwich, tart, bread, casserole, etc.), a model based on word occurrence will always occlude recipes made with ingredients less represented in the corpus.

Ultimately, Avery’s corpus is overly representative of a subgenre that she may not have acknowledged as distinct, but the computer definitely did: dessert recipe. According to Rachel Scarborough King, genre “represent[s] acts of association—made by writers, readers, critics, scholars, and/or computers—that generate usable configurations of texts” (King, 2021, p. 261). Acts of association, whether rooted in anything real or not, are made by a particular actor. We can use genre to learn something about the someone (or something) that associated these works together which might, in turn, tell us something about how they use them. In this case, Avery associated anything printed in a cookbook in 19th century America to fall under the genre “recipe.” The pattern she observed was based on bibliographic context. But the algorithm relied solely on words which made it unable to observe the same pattern/grouping as Avery did. Instead, the computer found distinctive words that were statistically likely to be part of a recipe. In doing so, it revealed that Avery’s corpus overly represented a subgenre, dessert recipe, that she had not initially considered.

## **Discussion**

I thought that the number of occurrences of the word raspberry in the dataset pointed towards the history of raspberries in the 19th century. I believed that the bias in the dataset had to do with a text being specific to an area of the country or a particular author, but I was wrong. The unbalanced corpus coupled with the word-based genre classifier caused the raspberry phenomenon.

Ultimately, the analysis can’t tell us much about the prevalence of raspberries in the 19th century at all. Instead, it examined corpus selection and algorithmic biases. This raises a difficult question that Ryan Dubnicek brought up in class: “at what scale of computational analysis do we stop studying the digital object and start studying the corpus creation?” I don’t have the answer to that question, but I do know that failure to engage with the processes through which these digital objects are born and treating them as surrogates, instead, is dangerous. After all, had I not bothered to analyze Avery’s corpus and our model and taken the results at face value, I would have reached the baseless conclusion that raspberries were the most popular food in 19th century America. At least now, I know what I cannot know.
